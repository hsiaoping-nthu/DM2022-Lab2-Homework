{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cdcf60d",
   "metadata": {},
   "source": [
    "# Decision Tree Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a178100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e67bedc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape:  (1455563, 5)\n",
      "test_df.shape:  (411972, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         hashtag  tweet_id  \\\n",
       "0                     [Snapchat]  0x376b20   \n",
       "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "3                             []  0x1cd5b0   \n",
       "5      [authentic, LaughOutLoud]  0x1d755c   \n",
       "6                             []  0x2c91a8   \n",
       "\n",
       "                                                text identification  \\\n",
       "0  People who post \"add me on #Snapchat\" must be ...          train   \n",
       "1  @brianklaas As we see, Trump is dangerous to #...          train   \n",
       "3                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>          train   \n",
       "5  @RISKshow @TheKevinAllison Thx for the BEST TI...          train   \n",
       "6       Still waiting on those supplies Liscus. <LH>          train   \n",
       "\n",
       "        emotion  \n",
       "0  anticipation  \n",
       "1       sadness  \n",
       "3          fear  \n",
       "5           joy  \n",
       "6  anticipation  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load a pickle file\n",
    "train_df = pd.read_pickle(\"train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"test_df.pkl\")\n",
    "\n",
    "print('train_df.shape: ', train_df.shape)\n",
    "print('test_df.shape: ', test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff4ea46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asked', 'asking', 'ass', 'at', 'august', 'away', 'awesome',\n",
       "       'awkward', 'baby', 'back'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(train_df['text'])\n",
    "vectorizer.get_feature_names_out()[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7820a788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hsiaoping.zhang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e57d4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsiaoping.zhang/tensorflow_macos_venv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>...</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>953.381953</td>\n",
       "      <td>1344.144443</td>\n",
       "      <td>1102.270872</td>\n",
       "      <td>1303.748394</td>\n",
       "      <td>1188.238455</td>\n",
       "      <td>1146.585667</td>\n",
       "      <td>1260.96394</td>\n",
       "      <td>1307.702982</td>\n",
       "      <td>1236.456253</td>\n",
       "      <td>1168.40325</td>\n",
       "      <td>...</td>\n",
       "      <td>2191.254503</td>\n",
       "      <td>1991.565798</td>\n",
       "      <td>6439.713886</td>\n",
       "      <td>4142.643848</td>\n",
       "      <td>4288.068357</td>\n",
       "      <td>2367.405908</td>\n",
       "      <td>4087.937808</td>\n",
       "      <td>1156.374577</td>\n",
       "      <td>1491.770708</td>\n",
       "      <td>1747.869507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           00         00am         00pm           01           02  \\\n",
       "0  953.381953  1344.144443  1102.270872  1303.748394  1188.238455   \n",
       "\n",
       "            03          04           05           06          07  ...  \\\n",
       "0  1146.585667  1260.96394  1307.702982  1236.456253  1168.40325  ...   \n",
       "\n",
       "            ya         yeah         year        years          yes  \\\n",
       "0  2191.254503  1991.565798  6439.713886  4142.643848  4288.068357   \n",
       "\n",
       "     yesterday          yet           yo        young      youtube  \n",
       "0  2367.405908  4087.937808  1156.374577  1491.770708  1747.869507  \n",
       "\n",
       "[1 rows x 1000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## baseline model : Random Forest\n",
    "import pickle\n",
    "\n",
    "tv = TfidfVectorizer(\n",
    "            ngram_range = (1,1), # ‰∏ÄÊ¨°ÊèêÂèñÂ§öÂ∞ëË©ûÁÇ∫‰∏ÄÂÄã feature ÊúÄÂ§ö‰∏ÄÊ¨°ÊèêÂèñ 1 ÂÄã ÊúÄÂ∞ë 1 ÂÄã\n",
    "            max_features = 1000, # ÊâæÂá∫ÊúÄÂ§öÂá∫ÁèæÁöÑ 1000 ÂÄãË©û,\n",
    "            stop_words=stopword,\n",
    "            token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "\n",
    "analyzer = tv.build_analyzer()\n",
    "title_train = tv.fit_transform(train_df['text'])\n",
    "pickle.dump(tv.vocabulary_, open(\"TFIDF_feature.pkl\",\"wb\"))\n",
    "\n",
    "vocab_titrain = tv.get_feature_names()\n",
    "dist = np.sum(title_train, axis=0)\n",
    "checking_train = pd.DataFrame(dist,columns = vocab_titrain)\n",
    "#checking_train.sort_values(by = 0, axis = 1, ascending = False)\n",
    "checking_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdc05426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "loaded_vec = CountVectorizer(vocabulary=pickle.load(open(\"TFIDF_feature.pkl\", \"rb\")))\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X = transformer.fit_transform(loaded_vec.fit_transform(train_df['text'])).toarray()\n",
    "y = train_df['emotion']\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f3eab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (975227, 1000)\n",
      "y_train.shape:  (975227,)\n",
      "X_val.shape:  (480336, 1000)\n",
      "y_val.shape:  (480336,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "x_test = transformer.fit_transform(loaded_vec.fit_transform(test_df['text'])).toarray()\n",
    "y_test = test_df['emotion']\n",
    "\n",
    "## take a look at data dimension is a good habit  :)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_val.shape: ', X_val.shape)\n",
    "print('y_val.shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea52729",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=22)\n",
    "\n",
    "## training!\n",
    "DT_model = DT_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_val_pred = DT_model.predict(X_val)\n",
    "\n",
    "## so we get the pred result\n",
    "y_val_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20259d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_val, y_pred=y_val_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('val accuracy: {}'.format(round(acc_val, 2)))\n",
    "\n",
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=y_val, y_pred=y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test = transformer.fit_transform(loaded_vec.fit_transform(test_df['text'])).toarray()\n",
    "y_test_pred = DT_model.predict(X_test)\n",
    "y_test_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf429aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['emotion'] = y_test_pred\n",
    "\n",
    "ans_df = test_df[['tweet_id', 'emotion']]\n",
    "ans_df = ans_df.rename(columns={\"tweet_id\": \"id\"})\n",
    "# ans_df.to_csv('answer_decision_tree.csv', index=False)\n",
    "print('finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
