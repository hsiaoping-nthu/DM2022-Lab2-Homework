{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: ÂºµÁ≠±Ëêç\n",
    "\n",
    "Student ID: `111065529`\n",
    "\n",
    "GitHub ID: `hsiaoping-nthu`\n",
    "\n",
    "Kaggle name: `yu`\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "<img src='screenshot.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2022-Lab2-master Repo](https://github.com/keziatamus/DM2022-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm2022-isa5810-lab2-homework) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/2b0d14a829f340bc88d2660dc602d4bd. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Nov. 22th 11:59 pm, Tuesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 25th 11:59 pm, Friday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         hashtag  tweet_id  \\\n",
       "0                     [Snapchat]  0x376b20   \n",
       "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                   [bibleverse]  0x28b412   \n",
       "3                             []  0x1cd5b0   \n",
       "4                             []  0x2de201   \n",
       "\n",
       "                                                text  \n",
       "0  People who post \"add me on #Snapchat\" must be ...  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...  \n",
       "2  Confident of your obedience, I write to you, k...  \n",
       "3                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>  \n",
       "4  \"Trust is not the same as faith. A friend is s...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# read json file\n",
    "data = []\n",
    "hashtags, tweet_ids, texts = [], [], []  # date information ?\n",
    "with open('dm2022-isa5810-lab2-homework/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)['_source']['tweet']\n",
    "        hashtags.append(item['hashtags'])\n",
    "        tweet_ids.append(item['tweet_id'])\n",
    "        texts.append(item['text'])\n",
    "\n",
    "# convert to dataframe and export to csv file\n",
    "df = pd.DataFrame(data={'hashtag': hashtags, 'tweet_id': tweet_ids, 'text': texts})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # concat tweets, identification, and emotion\n",
    "def merge_file_data():\n",
    "    \n",
    "    identification = pd.read_csv('dm2022-isa5810-lab2-homework/data_identification.csv', encoding= 'unicode_escape')\n",
    "    emotion = pd.read_csv('dm2022-isa5810-lab2-homework/emotion.csv')\n",
    "    \n",
    "    temp_df = pd.merge(identification, emotion, how=\"left\")\n",
    "    all_df = pd.merge(df, temp_df)\n",
    "\n",
    "    ## save data\n",
    "    train_df = all_df[all_df.identification == 'train']\n",
    "    test_df = all_df[all_df.identification == 'test']\n",
    "\n",
    "    train_df.to_pickle(\"train_df.pkl\") \n",
    "    test_df.to_pickle(\"test_df.pkl\")\n",
    "\n",
    "    print('train_df.shape: ', train_df.shape)\n",
    "    print('test_df.shape: ', test_df.shape)\n",
    "    \n",
    "merge_file_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape:  (1455563, 5)\n",
      "test_df.shape:  (411972, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         hashtag  tweet_id  \\\n",
       "0                     [Snapchat]  0x376b20   \n",
       "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "3                             []  0x1cd5b0   \n",
       "5      [authentic, LaughOutLoud]  0x1d755c   \n",
       "6                             []  0x2c91a8   \n",
       "\n",
       "                                                text identification  \\\n",
       "0  People who post \"add me on #Snapchat\" must be ...          train   \n",
       "1  @brianklaas As we see, Trump is dangerous to #...          train   \n",
       "3                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>          train   \n",
       "5  @RISKshow @TheKevinAllison Thx for the BEST TI...          train   \n",
       "6       Still waiting on those supplies Liscus. <LH>          train   \n",
       "\n",
       "        emotion  \n",
       "0  anticipation  \n",
       "1       sadness  \n",
       "3          fear  \n",
       "5           joy  \n",
       "6  anticipation  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load a pickle file\n",
    "train_df = pd.read_pickle(\"train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"test_df.pkl\")\n",
    "\n",
    "print('train_df.shape: ', train_df.shape)\n",
    "print('test_df.shape: ', test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# the histogram of the data\n",
    "labels = train_df['emotion'].unique()\n",
    "post_total = len(train_df)\n",
    "df1 = train_df.groupby(['emotion']).count()['text']\n",
    "df1 = df1.apply(lambda x: round(x*100/post_total,3))\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "plt.bar(df1.index,df1.values)\n",
    "\n",
    "# arrange\n",
    "plt.ylabel('% of instances')\n",
    "plt.xlabel('Emotion')\n",
    "plt.title('Emotion distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featue Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asked', 'asking', 'ass', 'at', 'august', 'away', 'awesome',\n",
       "       'awkward', 'baby', 'back'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(train_df['text'])\n",
    "vectorizer.get_feature_names_out()[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hsiaoping.zhang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape:  (1455563, 5)\n",
      "test_df.shape:  (411972, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         hashtag  tweet_id  \\\n",
       "0                     [Snapchat]  0x376b20   \n",
       "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "3                             []  0x1cd5b0   \n",
       "5      [authentic, LaughOutLoud]  0x1d755c   \n",
       "6                             []  0x2c91a8   \n",
       "\n",
       "                                                text identification  \\\n",
       "0  People who post \"add me on #Snapchat\" must be ...          train   \n",
       "1  @brianklaas As we see, Trump is dangerous to #...          train   \n",
       "3                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>          train   \n",
       "5  @RISKshow @TheKevinAllison Thx for the BEST TI...          train   \n",
       "6       Still waiting on those supplies Liscus. <LH>          train   \n",
       "\n",
       "        emotion  \n",
       "0  anticipation  \n",
       "1       sadness  \n",
       "3          fear  \n",
       "5           joy  \n",
       "6  anticipation  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load a pickle file\n",
    "train_df = pd.read_pickle(\"train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"test_df.pkl\")\n",
    "\n",
    "print('train_df.shape: ', train_df.shape)\n",
    "print('test_df.shape: ', test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# filter with stopnwords may help performance\n",
    "nltk.download('stopwords')\n",
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsiaoping\\AppData\\Local\\Temp\\ipykernel_18544\\3249289237.py:9: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  X_train, X_test, y_train, y_test = train_test_split(train_df['text'][:total_train_count//5], train_df['emotion'][:total_train_count//5], test_size=0.30, random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 326,    8,   28, 2127,   12,  445,    7,  284,    8,   34,    9,\n",
       "         273, 9986,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "MAX_NUM_WORDS = 15000\n",
    "total_train_count = len(train_df['text'])\n",
    "train_fraction = 4\n",
    "\n",
    "# Split train and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_df['text'][:total_train_count//train_fraction], train_df['emotion'][:total_train_count//train_fraction], test_size=0.30, random_state=42)\n",
    "\n",
    "y = train_df['emotion']\n",
    "\n",
    "# Binarize labels with SKLearn label binarizer\n",
    "encoder = LabelBinarizer()\n",
    "y_train = encoder.fit_transform(Y_train)\n",
    "y_test = encoder.fit_transform(Y_test)\n",
    "\n",
    "# # Tokenize sentencs to numbers with max number 10000\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 25\n",
    "\n",
    "# Pad sequences to max length with post padding.\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resource : [glove.6B.100d.txt](https://www.kaggle.com/datasets/danielwillgeorge/glove6b100dtxt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Creating model\n"
     ]
    }
   ],
   "source": [
    "# Load embedding file\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "with open('glove.6B.100d.txt', encoding=\"utf8\") as glove_file:\n",
    "    for line in glove_file:\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "        embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "print(\"INFO: Creating model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " module_wrapper_9 (ModuleWra  (None, 25, 100)          21516400  \n",
      " pper)                                                           \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 25, 100)          60400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 120)              77280     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " module_wrapper_10 (ModuleWr  (None, 64)               7744      \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_11 (ModuleWr  (None, 8)                520       \n",
      " apper)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,662,344\n",
      "Trainable params: 145,944\n",
      "Non-trainable params: 21,516,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.python.keras.layers.embeddings import Embedding\n",
    "from tensorflow.python.keras.layers.core import Activation, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, LSTM, Bidirectional, Conv1D\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "\n",
    "# Create a Keras LSTM model with bidirectional layers\n",
    "model = Sequential([\n",
    "    Input(shape=(MAX_SEQUENCE_LENGTH,),dtype='int32'),\n",
    "    Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False),\n",
    "    Bidirectional(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)),\n",
    "    Bidirectional(LSTM(60, dropout=0.3, recurrent_dropout=0.3)),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(8, activation=\"softmax\")])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Starting training\n",
      "Epoch 1/10\n",
      "2229/2229 [==============================] - 158s 68ms/step - loss: 1.5323 - accuracy: 0.4362 - val_loss: 1.4296 - val_accuracy: 0.4774\n",
      "Epoch 2/10\n",
      "2229/2229 [==============================] - 145s 65ms/step - loss: 1.4139 - accuracy: 0.4838 - val_loss: 1.3690 - val_accuracy: 0.4994\n",
      "Epoch 3/10\n",
      "2229/2229 [==============================] - 147s 66ms/step - loss: 1.3651 - accuracy: 0.5034 - val_loss: 1.3445 - val_accuracy: 0.5087\n",
      "Epoch 4/10\n",
      "2229/2229 [==============================] - 143s 64ms/step - loss: 1.3340 - accuracy: 0.5139 - val_loss: 1.3195 - val_accuracy: 0.5204\n",
      "Epoch 5/10\n",
      "2229/2229 [==============================] - 146s 66ms/step - loss: 1.3108 - accuracy: 0.5231 - val_loss: 1.3044 - val_accuracy: 0.5254\n",
      "Epoch 6/10\n",
      "2229/2229 [==============================] - 148s 66ms/step - loss: 1.2915 - accuracy: 0.5303 - val_loss: 1.2975 - val_accuracy: 0.5302\n",
      "Epoch 7/10\n",
      "2229/2229 [==============================] - 149s 67ms/step - loss: 1.2767 - accuracy: 0.5367 - val_loss: 1.2934 - val_accuracy: 0.5307\n",
      "Epoch 8/10\n",
      "2229/2229 [==============================] - 153s 69ms/step - loss: 1.2653 - accuracy: 0.5391 - val_loss: 1.2881 - val_accuracy: 0.5334\n",
      "Epoch 9/10\n",
      "2229/2229 [==============================] - 146s 66ms/step - loss: 1.2545 - accuracy: 0.5438 - val_loss: 1.2810 - val_accuracy: 0.5348\n",
      "Epoch 10/10\n",
      "2229/2229 [==============================] - 147s 66ms/step - loss: 1.2454 - accuracy: 0.5469 - val_loss: 1.2705 - val_accuracy: 0.5398\n",
      "INFO: Saving models done\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"INFO: Starting training\")\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.3)\n",
    "print(\"INFO: Model done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3412/3412 [==============================] - 23s 7ms/step\n",
      "predict:\n",
      " [[0.07564802 0.19193272 0.14714912 0.03386658 0.18761043 0.22362651\n",
      "  0.03031613 0.10985048]\n",
      " [0.00341474 0.05610247 0.01268725 0.00512961 0.5521433  0.20591904\n",
      "  0.01130412 0.15329953]\n",
      " [0.02771143 0.29375458 0.0680461  0.07472917 0.21776035 0.10304779\n",
      "  0.03458373 0.18036683]\n",
      " [0.00092014 0.06151075 0.0024783  0.00471788 0.6007446  0.00867123\n",
      "  0.00789956 0.31305748]\n",
      " [0.0121926  0.02273299 0.22455041 0.01118193 0.01990461 0.6606399\n",
      "  0.03300128 0.0157963 ]] - - -\n",
      "convert:\n",
      " ['sadness' 'joy' 'anticipation' 'joy' 'sadness']\n"
     ]
    }
   ],
   "source": [
    "# predict answer\n",
    "test_predictions = model.predict(X_test)\n",
    "print('predict:\\n', test_predictions[:5], '- - -')\n",
    "\n",
    "# convert to emotion words\n",
    "test_predictions_original = encoder.inverse_transform(test_predictions)\n",
    "print('convert:\\n', test_predictions_original[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.59      0.21      0.31      2891\n",
      "anticipation       0.64      0.57      0.60     18614\n",
      "     disgust       0.50      0.33      0.39     10446\n",
      "        fear       0.74      0.32      0.45      4852\n",
      "         joy       0.54      0.83      0.66     38882\n",
      "     sadness       0.44      0.51      0.47     14433\n",
      "    surprise       0.80      0.17      0.28      3590\n",
      "       trust       0.68      0.26      0.37     15459\n",
      "\n",
      "    accuracy                           0.55    109167\n",
      "   macro avg       0.62      0.40      0.44    109167\n",
      "weighted avg       0.58      0.55      0.53    109167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=Y_test, y_pred=test_predictions_original)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print(classification_report(y_true=Y_test, y_pred=test_predictions_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict private set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411972"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# private dataset is the competition dataset we need to predict\n",
    "X_private = tokenizer.texts_to_sequences(test_df['text'])\n",
    "X_private = pad_sequences(X_private, padding='post', maxlen=maxlen)\n",
    "len(X_private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12875/12875 [==============================] - 531s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'anticipation', 'sadness', 'joy', 'anticipation'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_predictions = model.predict(X_private)\n",
    "private_predictions_original = encoder.inverse_transform(private_predictions)\n",
    "private_predictions_original[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "test_df['emotion'] = private_predictions_original\n",
    "\n",
    "ans_df = test_df[['tweet_id', 'emotion']]\n",
    "ans_df = ans_df.rename(columns={\"tweet_id\": \"id\"})\n",
    "ans_df.to_csv('answer.csv', index=False)  # write to file\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "loaded_vec = CountVectorizer(vocabulary=pickle.load(open(\"TFIDF_feature.pkl\", \"rb\")))\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X = transformer.fit_transform(loaded_vec.fit_transform(train_df['text'])).toarray()\n",
    "y = train_df['emotion']\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (975227, 1000)\n",
      "y_train.shape:  (975227,)\n",
      "X_val.shape:  (480336, 1000)\n",
      "y_val.shape:  (480336,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "x_test = transformer.fit_transform(loaded_vec.fit_transform(test_df['text'])).toarray()\n",
    "y_test = test_df['emotion']\n",
    "\n",
    "## take a look at data dimension is a good habit  :)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_val.shape: ', X_val.shape)\n",
    "print('y_val.shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " 247522     trust\n",
      "1563748      joy\n",
      "651597       joy\n",
      "583951       joy\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (975227,)\n",
      "y_val.shape:  (480336,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (975227, 8)\n",
      "y_val.shape:  (480336, 8)\n"
     ]
    }
   ],
   "source": [
    "# baseline method\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_val.shape: ', y_val.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_val = label_encode(label_encoder, y_val)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_val.shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  1000\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1000)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                64064     \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 68,744\n",
      "Trainable params: 68,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.layers import ReLU, Softmax\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=64)(X)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=64)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2c830b040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2c830b040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 16:54:58.287352: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-11-18 16:54:58.289540: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30445/30476 [============================>.] - ETA: 0s - loss: 1.4559 - accuracy: 0.4740 ETA: 2s - loss: 1.4641 - accuracy: 0.47 - ETA: 1s - loss: - ETA: 1s - loss: 1 - ETA: 0s - loss: 1.4595 - accuracy: 0.47 - ETA: 0sWARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2c06030d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2c06030d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "30476/30476 [==============================] - 18s 600us/step - loss: 1.4558 - accuracy: 0.4740 - val_loss: 1.3791 - val_accuracy: 0.4974\n",
      "Epoch 2/10\n",
      "30476/30476 [==============================] - 15s 498us/step - loss: 1.3624 - accuracy: 0.5022 - val_loss: 1.3632 - val_accuracy: 0.5018\n",
      "Epoch 3/10\n",
      "30476/30476 [==============================] - 15s 485us/step - loss: 1.3424 - accuracy: 0.5094 - val_loss: 1.3588 - val_accuracy: 0.5031\n",
      "Epoch 4/10\n",
      "30476/30476 [==============================] - 16s 515us/step - loss: 1.3308 - accuracy: 0.5124 - val_loss: 1.3601 - val_accuracy: 0.5036\n",
      "Epoch 5/10\n",
      "30476/30476 [==============================] - 15s 496us/step - loss: 1.3250 - accuracy: 0.5153 - val_loss: 1.3608 - val_accuracy: 0.5034\n",
      "Epoch 6/10\n",
      "30476/30476 [==============================] - 15s 485us/step - loss: 1.3183 - accuracy: 0.5176 - val_loss: 1.3611 - val_accuracy: 0.5045\n",
      "Epoch 7/10\n",
      "30476/30476 [==============================] - 15s 489us/step - loss: 1.3129 - accuracy: 0.5199 - val_loss: 1.3601 - val_accuracy: 0.5039\n",
      "Epoch 8/10\n",
      "30476/30476 [==============================] - 15s 486us/step - loss: 1.3128 - accuracy: 0.5210 - val_loss: 1.3633 - val_accuracy: 0.5025\n",
      "Epoch 9/10\n",
      "30476/30476 [==============================] - 16s 532us/step - loss: 1.3068 - accuracy: 0.5226 - val_loss: 1.3649 - val_accuracy: 0.5034\n",
      "Epoch 10/10\n",
      "30476/30476 [==============================] - 16s 510us/step - loss: 1.3037 - accuracy: 0.5239 - val_loss: 1.3645 - val_accuracy: 0.5035\n",
      "training finish\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size,\n",
    "                    validation_data = (X_val, y_val))\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'joy', 'joy', 'anticipation'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result_val[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2c83b9670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2c83b9670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rd/0nr5tzsn2z17vy9fjcj5rlsc0000gn/T/ipykernel_80679/4060053461.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# pred_result_val[:5]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0macc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_result_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow_macos_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow_macos_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "## validation result\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_result_val = model.predict(X_val, batch_size=128)\n",
    "pred_result_val = label_decode(label_encoder, pred_result_val)\n",
    "\n",
    "acc_val = accuracy_score(y_true=y_val, y_pred=pred_result_val)\n",
    "\n",
    "print('val accuracy: {}'.format(round(acc_val, 2)))\n",
    "\n",
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=y_val, y_pred=pred_result_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4010618e-02, 2.3327893e-01, 5.0355934e-02, 1.5532605e-02,\n",
       "        4.7398803e-01, 8.6497433e-02, 1.7633773e-02, 1.0870266e-01],\n",
       "       [2.8921964e-03, 6.7801422e-01, 5.3848973e-03, 7.8308238e-03,\n",
       "        8.6882323e-02, 7.3034544e-03, 4.9636140e-03, 2.0672847e-01],\n",
       "       [3.5215262e-02, 6.1228216e-02, 3.0504775e-01, 6.4646821e-03,\n",
       "        2.3467743e-01, 1.8142213e-01, 2.9762523e-02, 1.4618208e-01],\n",
       "       [3.8434294e-04, 3.5049424e-02, 3.5597985e-03, 1.6453075e-03,\n",
       "        8.6833477e-01, 1.0229127e-03, 3.8350557e-04, 8.9619920e-02],\n",
       "       [2.0002207e-02, 2.3798883e-01, 7.4520566e-02, 5.4311875e-02,\n",
       "        2.8611848e-01, 9.1158509e-02, 2.5483822e-02, 2.1041575e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict\n",
    "pred_result = model.predict(x_test, batch_size=128)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'anticipation', 'disgust', 'joy', 'joy'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = label_decode(label_encoder, pred_result)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "test_df['emotion'] = pred_result\n",
    "\n",
    "ans_df = test_df[['tweet_id', 'emotion']]\n",
    "ans_df = ans_df.rename(columns={\"tweet_id\": \"id\"})\n",
    "ans_df.to_csv('answer_baseline.csv', index=False)\n",
    "print('finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
